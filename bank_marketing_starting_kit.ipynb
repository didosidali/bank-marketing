{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center><B>Data Camp project - RAMP on Bank Marketing Data Set</B></center></h1>\n",
    "<center><I>M2 AIC - Univsersité Paris-Saclay - 2018-2019</I></center>\n",
    "<br>\n",
    "<center>Sid Ali HAMIDECHE, Youcef MADJI, Aurélien Mascaro, Mohamed Khalil JABRI, Yacine YAKOUBI</center>\n",
    "<br>\n",
    "<center>Teachers : Alexandre GRAMFORT, Balazs KEGL</center><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h2><B><U>Table of Contents</U></B></h2>\n",
    "\n",
    "<a href=\"#EL_010\">1. Introduction</a><br>\n",
    "&emsp;<a href=\"#EL_011\">1.1 Business case</a><br>\n",
    "&emsp;<a href=\"#EL_012\">1.2 Context</a><br>\n",
    "\n",
    "<a href=\"#EL_020\">2. Project</a><br>\n",
    "&emsp;<a href=\"#EL_021\">2.1 Prerequisites</a><br>\n",
    "&emsp;<a href=\"#EL_022\">2.2 The data</a><br>\n",
    "&emsp;<a href=\"#EL_023\">2.3 Goals</a><br>\n",
    "\n",
    "<a href=\"#EL_030\">3. Data analysis</a><br>\n",
    "&emsp;<a href=\"#EL_031\">3.1 Overall data's statistics</a><br>\n",
    "&emsp;<a href=\"#EL_032\">3.2 Data visualization</a><br>\n",
    "&emsp;<a href=\"#EL_033\">3.3 Examples</a><br>\n",
    "\n",
    "<a href=\"#EL_040\">4. Models & Metrics</a><br>\n",
    "&emsp;<a href=\"#EL_041\">4.1 Features engineering</a><br>\n",
    "&emsp;<a href=\"#EL_042\">4.2 Classifiers</a><br>\n",
    "&emsp;<a href=\"#EL_043\">4.3 Evaluation metrics</a><br>\n",
    "&emsp;<a href=\"#EL_044\">4.4 Testing</a><br>\n",
    "\n",
    "<a href=\"#EL_050\">5. The challenge</a><br>\n",
    "&emsp;<a href=\"#EL_051\">5.1 The model to submit</a><br>\n",
    "&emsp;<a href=\"#EL_052\">5.2 Local testing</a><br>\n",
    "&emsp;<a href=\"#EL_053\">5.3 Submitting on RAMP</a><br>\n",
    "&emsp;<a href=\"#EL_054\">5.4 More informations</a><br>\n",
    "\n",
    "<a href=\"#EL_060\">6. Hints</a><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"EL_001\"><h2><center>1. Introduction</center></h2></a>\n",
    "\n",
    "<a id=\"EL_011\"><h3>1.1 Business case</h3></a>\n",
    "\n",
    "Marketing campaigns are a typicaal situation where companies enhance business by targeting segments of customers when they want  to meet a specific goal. Collecting customer remote interaction is a good way to ease and analyse the results from the marketing campaigns. Contact centers allow communication with the customers by different means with telephone being for most used one.\n",
    "Such marketing contact is called telemarketing because of the remoteness.\n",
    "With each contact we can wonder who triggered the contact : the phone call center or the customer. Depending of the side who triggered, challenges may differ. Indeed, some of the calls may be considered as intrusive if it's coming from a call center.\n",
    "The point is that thanks to technology, we can completely rethink marketing in the way that we can now focus on a long duration value of a customer by using metrics and evualuation of the available informations. By such a way of rethinking marketing, we can then build a longer and a much more accurate business relation between the customers and a company.\n",
    "<I>Decision Support Systems</I>, also called DSSs, use those new means that technology provide in order to help managerial decision making. However, such systems can specialize in multiple fields. Indeed, some of those systems are rather focused on helping one manager on small-scale systems to take a decision, while some others use AI to help in decision making.\n",
    "\n",
    "We can also talk about <I>Business Intelligence</I> (BI), which uses the concept of such systems in many ways in order to help in decision making thanks to the business data : it uses data mining, information technologies, etc...\n",
    "\n",
    "In a way, we can compare our project with <I>Data Mining</I> since in such cases, it also allows to explore and study a business case.\n",
    "The point is that it plays a role with efficient Decision Support Systems and thus, this field also allows the semi-automatic extraction of explanatory and predictive knowledge from raw data.\n",
    "\n",
    "Indeed, Machine Learning is a data science field dedicated to build models in order to make classification by by characterizing inputs with labels as output.<br><br>\n",
    "\n",
    "<img src=\"./img/bank-marketing.jpg\" width=\"100%\">\n",
    "<br>\n",
    "<a id=\"EL_012\"><h3>1.2 Context</h3></a>\n",
    "\n",
    "In data science, there is many models of classification : from the well-knows Logistic Regression up to the more recent <I>Support Vector Machines</I> (SVM), passing by the unavoidables Neural Networks often used in data science.\n",
    "The reason for this amount of models to co-exist at the same time is the advantages some of them can give depending of the situation.\n",
    "\n",
    "For example, the Logistic Regression is a very good model to use when it's about to fit models human can also easily understand and so, it gives a good prediction and clasification rate. On the other hand, models such as Support Vector Machines or even Neural Networks are so flexible that it allows doing very accurate predictions but making the models almost unintelligible for humans.\n",
    "\n",
    "However, those models, which can be compared to black box models allow to measure both importance and effect of specific inputs to the outputs generated.\n",
    "\n",
    "When we compare all the models, we can see very high differences between their performances. It's important to take in count those differences since it emphasizes the impact of the problem context and is the reason to test as much possible techniques as possible before choosing a specific one when it's addressed to a given problem.\n",
    "\n",
    "Above the models consideration, it's important to note both Business Intelligence and Decision Support Systems are unavoidable fields of banking since it can be applied to almost every banking domain. Despite being useful, such methodology hasn't been applied to very specific banking problems such as the aim of our project, for instance the customers targeting.\n",
    "\n",
    "In this project, we will study how to build models able to automatically predict the result of a phone call having for objective to propose a service to a customer. Such models are very valuable for managers since it's of a very efficient help when it's about to select and priotize the customers to contact because this will highly improve the success of such phone calls by lowering the amount of phone calls having a great probability to fail. This has for advantage to directly and greatly lower the time and cost put in such efforts and give a better opinion of customers contacted since the successful calls will give a return on investment and the avoided failed calls won't have the reputation importune or even be intrusive to a potential customer population.\n",
    "\n",
    "We will introduce below the main key points of the project which are :\n",
    "- <I>The dataset in general :</I> an analysis of this dataset will ease understanding its organization and the wau it has been built.\n",
    "- <I>The feature engineering :</I> what kind of features exist and how are they (or should they be) managed.\n",
    "- <I>The output :</I> in order to evaluation the generated models we have to introduce how are their efficiency are measured and also on what kind of models.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"EL_020\"><h2><center>2. Project</center></h2></a>\n",
    "\n",
    "⚠ In order to correctly run this notebook, please download the full starting kit, with all the necessary files.\n",
    "\n",
    "<a id=\"EL_021\"><h3>2.1 Prerequisites</h3></a>\n",
    "\n",
    "This starting kit requires some dependencies.\n",
    "<br>Don't forget to check the <B>requirement.txt</B> file in order to know what you will need.\n",
    "\n",
    "\n",
    "\n",
    "We recommend to install those using conda (using the Anaconda distribution).\n",
    "\n",
    "In addition, ramp-workflow is needed. This can be installed from the master branch on GitHub:\n",
    "python -m pip install https://api.github.com/repos/paris-saclay-cds/ramp-workflow/zipball/master\n",
    "\n",
    "\n",
    "\n",
    "<a id=\"EL_022\"><h3>2.2 The data</h3></a>\n",
    "\n",
    "The data is a about a Portuguese retail banking institution which collected data from 2008 to 2010. The interesting point of this dataset is that it also contains the effect of a financial crisis which occured the same time the data was collected.\n",
    "\n",
    "The dataset contains 19 interesting features related to : customers, calls, social/economic context attributes and other attributes (about the campaign, etc...).\n",
    "The files used to work on this project are named \"bank.zip\" and \"bank-additional.zip\".\n",
    "The main differences between these files are the amount of inputs (17 versus 20) and the duration of the data ordered and collected.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><a id=\"EL_030\"><h2>3. Data analysis</h2></a></center><br>\n",
    "\n",
    "In this part, we will focus on the details of the dataset and, of course, we will present you a few methods to read the data / summarize the most interesting informations in order to get a better and more global overview of the studied dataset.\n",
    "\n",
    "<a id=\"EL_031\"><h3>3.1 Overall data's statistics</h3></a>\n",
    "\n",
    "This part is an explanation of the statistics we can view.\n",
    "\n",
    "The research focuses on targeting telemarketing phone calls to subscribe term deposits (our y output variable). During a campaign, a company execute phone calls to a designed list of clients in order to sell deposits or, in the opposite case where the customer is the one contacting the company, he is proposed to subscribe the deposit.\n",
    "In any of the two cases, everything is about successful or failed attempt to sell the deposit after a contact.\n",
    "\n",
    "This study considers real data collected from May 2008 to November 2010 in a total of 45,211 phone calls.\n",
    "There is no missing value within the database and less than 10% of the records are considered as successful (a \"yes\" answer after the phone call).\n",
    "In order to make evaluations, the complete data has been split, artificially, between two sub-categories of data : the training data and the test data.\n",
    "Of course, the test data is only used to measure prediction capabilities of the selected data-driven model.\n",
    "\n",
    "We remind you that we have a total of 19 features.\n",
    "\n",
    "<a id=\"EL_032\"><h3>3.2 Data visualization</h3></a>\n",
    "\n",
    "Below is the representation of the data as it can be exploited during the project.\n",
    "\n",
    "The dataset can be downloaded at : https://archive.ics.uci.edu/ml/datasets/Bank+Marketing\n",
    "\n",
    "<a id=\"EL_033\"><h3>3.3 Examples</h3></a>\n",
    "\n",
    "Beyond showing the full statistics of the dataset, it's interesting to focus on inputs by themselves. Indeed, it can be interesting to look at some inputs such as age in order to know if the dataset contains a huge distribution on some inputs or if it's very limited and thus, requiring a very limited interest in such inputs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/data_test.csv already exists\r\n",
      "data/data_train.csv already exists\r\n",
      "data/labels_test.npy already exists\r\n",
      "data/labels_train.npy already exists\r\n"
     ]
    }
   ],
   "source": [
    "!python ./download_data.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory data analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from problem import get_train_data\n",
    "X_train ,y_train = get_train_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>emp.var.rate</th>\n",
       "      <th>cons.price.idx</th>\n",
       "      <th>cons.conf.idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr.employed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>42</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.4y</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>tue</td>\n",
       "      <td>3</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.856</td>\n",
       "      <td>5191.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>51</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.4y</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>43</td>\n",
       "      <td>entrepreneur</td>\n",
       "      <td>married</td>\n",
       "      <td>professional.course</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>may</td>\n",
       "      <td>fri</td>\n",
       "      <td>4</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>-1.8</td>\n",
       "      <td>92.893</td>\n",
       "      <td>-46.2</td>\n",
       "      <td>1.250</td>\n",
       "      <td>5099.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>46</td>\n",
       "      <td>admin.</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>wed</td>\n",
       "      <td>4</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.858</td>\n",
       "      <td>5191.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36</td>\n",
       "      <td>services</td>\n",
       "      <td>single</td>\n",
       "      <td>basic.9y</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>fri</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>37</td>\n",
       "      <td>technician</td>\n",
       "      <td>single</td>\n",
       "      <td>university.degree</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>thu</td>\n",
       "      <td>5</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.860</td>\n",
       "      <td>5191.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>43</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>wed</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>25</td>\n",
       "      <td>services</td>\n",
       "      <td>single</td>\n",
       "      <td>basic.9y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>jun</td>\n",
       "      <td>thu</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>-1.7</td>\n",
       "      <td>94.055</td>\n",
       "      <td>-39.8</td>\n",
       "      <td>0.742</td>\n",
       "      <td>4991.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>53</td>\n",
       "      <td>management</td>\n",
       "      <td>married</td>\n",
       "      <td>university.degree</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>jun</td>\n",
       "      <td>tue</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.4</td>\n",
       "      <td>94.465</td>\n",
       "      <td>-41.8</td>\n",
       "      <td>4.961</td>\n",
       "      <td>5228.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>32</td>\n",
       "      <td>unknown</td>\n",
       "      <td>single</td>\n",
       "      <td>professional.course</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>jul</td>\n",
       "      <td>thu</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.4</td>\n",
       "      <td>93.918</td>\n",
       "      <td>-42.7</td>\n",
       "      <td>4.963</td>\n",
       "      <td>5228.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age           job  marital            education  default  housing     loan  \\\n",
       "0   42   blue-collar  married             basic.4y  unknown       no       no   \n",
       "1   51   blue-collar  married             basic.4y  unknown  unknown  unknown   \n",
       "2   43  entrepreneur  married  professional.course       no       no       no   \n",
       "3   46        admin.  married          high.school       no      yes       no   \n",
       "4   36      services   single             basic.9y  unknown       no      yes   \n",
       "5   37    technician   single    university.degree       no       no       no   \n",
       "6   43      services  married          high.school  unknown       no       no   \n",
       "7   25      services   single             basic.9y       no       no       no   \n",
       "8   53    management  married    university.degree  unknown       no       no   \n",
       "9   32       unknown   single  professional.course       no       no       no   \n",
       "\n",
       "     contact month day_of_week  campaign  pdays  previous     poutcome  \\\n",
       "0  telephone   may         tue         3    999         0  nonexistent   \n",
       "1  telephone   may         mon         1    999         0  nonexistent   \n",
       "2   cellular   may         fri         4    999         0  nonexistent   \n",
       "3  telephone   may         wed         4    999         0  nonexistent   \n",
       "4  telephone   may         fri         1    999         0  nonexistent   \n",
       "5  telephone   may         thu         5    999         0  nonexistent   \n",
       "6  telephone   may         wed         1    999         0  nonexistent   \n",
       "7  telephone   jun         thu         1    999         0  nonexistent   \n",
       "8  telephone   jun         tue         1    999         0  nonexistent   \n",
       "9  telephone   jul         thu         1    999         0  nonexistent   \n",
       "\n",
       "   emp.var.rate  cons.price.idx  cons.conf.idx  euribor3m  nr.employed  \n",
       "0           1.1          93.994          -36.4      4.856       5191.0  \n",
       "1           1.1          93.994          -36.4      4.857       5191.0  \n",
       "2          -1.8          92.893          -46.2      1.250       5099.1  \n",
       "3           1.1          93.994          -36.4      4.858       5191.0  \n",
       "4           1.1          93.994          -36.4      4.857       5191.0  \n",
       "5           1.1          93.994          -36.4      4.860       5191.0  \n",
       "6           1.1          93.994          -36.4      4.857       5191.0  \n",
       "7          -1.7          94.055          -39.8      0.742       4991.6  \n",
       "8           1.4          94.465          -41.8      4.961       5228.1  \n",
       "9           1.4          93.918          -42.7      4.963       5228.1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 32950 entries, 0 to 32949\n",
      "Data columns (total 19 columns):\n",
      "age               32950 non-null int64\n",
      "job               32950 non-null object\n",
      "marital           32950 non-null object\n",
      "education         32950 non-null object\n",
      "default           32950 non-null object\n",
      "housing           32950 non-null object\n",
      "loan              32950 non-null object\n",
      "contact           32950 non-null object\n",
      "month             32950 non-null object\n",
      "day_of_week       32950 non-null object\n",
      "campaign          32950 non-null int64\n",
      "pdays             32950 non-null int64\n",
      "previous          32950 non-null int64\n",
      "poutcome          32950 non-null object\n",
      "emp.var.rate      32950 non-null float64\n",
      "cons.price.idx    32950 non-null float64\n",
      "cons.conf.idx     32950 non-null float64\n",
      "euribor3m         32950 non-null float64\n",
      "nr.employed       32950 non-null float64\n",
      "dtypes: float64(5), int64(4), object(10)\n",
      "memory usage: 4.8+ MB\n"
     ]
    }
   ],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age               0\n",
       "job               0\n",
       "marital           0\n",
       "education         0\n",
       "default           0\n",
       "housing           0\n",
       "loan              0\n",
       "contact           0\n",
       "month             0\n",
       "day_of_week       0\n",
       "campaign          0\n",
       "pdays             0\n",
       "previous          0\n",
       "poutcome          0\n",
       "emp.var.rate      0\n",
       "cons.price.idx    0\n",
       "cons.conf.idx     0\n",
       "euribor3m         0\n",
       "nr.employed       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>emp.var.rate</th>\n",
       "      <th>cons.price.idx</th>\n",
       "      <th>cons.conf.idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr.employed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>32950.000000</td>\n",
       "      <td>32950.000000</td>\n",
       "      <td>32950.000000</td>\n",
       "      <td>32950.000000</td>\n",
       "      <td>32950.000000</td>\n",
       "      <td>32950.000000</td>\n",
       "      <td>32950.000000</td>\n",
       "      <td>32950.000000</td>\n",
       "      <td>32950.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>40.005250</td>\n",
       "      <td>2.565008</td>\n",
       "      <td>962.204279</td>\n",
       "      <td>0.175053</td>\n",
       "      <td>0.087821</td>\n",
       "      <td>93.577549</td>\n",
       "      <td>-40.494607</td>\n",
       "      <td>3.628984</td>\n",
       "      <td>5167.315044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>10.408699</td>\n",
       "      <td>2.777757</td>\n",
       "      <td>187.576207</td>\n",
       "      <td>0.501486</td>\n",
       "      <td>1.569263</td>\n",
       "      <td>0.579108</td>\n",
       "      <td>4.626925</td>\n",
       "      <td>1.731411</td>\n",
       "      <td>72.264825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-3.400000</td>\n",
       "      <td>92.201000</td>\n",
       "      <td>-50.800000</td>\n",
       "      <td>0.634000</td>\n",
       "      <td>4963.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>32.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>999.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.800000</td>\n",
       "      <td>93.075000</td>\n",
       "      <td>-42.700000</td>\n",
       "      <td>1.344000</td>\n",
       "      <td>5099.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>38.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>999.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>93.749000</td>\n",
       "      <td>-41.800000</td>\n",
       "      <td>4.857000</td>\n",
       "      <td>5191.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>47.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>999.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.400000</td>\n",
       "      <td>93.994000</td>\n",
       "      <td>-36.400000</td>\n",
       "      <td>4.961000</td>\n",
       "      <td>5228.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>98.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>999.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.400000</td>\n",
       "      <td>94.767000</td>\n",
       "      <td>-26.900000</td>\n",
       "      <td>5.045000</td>\n",
       "      <td>5228.100000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                age      campaign         pdays      previous  emp.var.rate  \\\n",
       "count  32950.000000  32950.000000  32950.000000  32950.000000  32950.000000   \n",
       "mean      40.005250      2.565008    962.204279      0.175053      0.087821   \n",
       "std       10.408699      2.777757    187.576207      0.501486      1.569263   \n",
       "min       17.000000      1.000000      0.000000      0.000000     -3.400000   \n",
       "25%       32.000000      1.000000    999.000000      0.000000     -1.800000   \n",
       "50%       38.000000      2.000000    999.000000      0.000000      1.100000   \n",
       "75%       47.000000      3.000000    999.000000      0.000000      1.400000   \n",
       "max       98.000000     56.000000    999.000000      7.000000      1.400000   \n",
       "\n",
       "       cons.price.idx  cons.conf.idx     euribor3m   nr.employed  \n",
       "count    32950.000000   32950.000000  32950.000000  32950.000000  \n",
       "mean        93.577549     -40.494607      3.628984   5167.315044  \n",
       "std          0.579108       4.626925      1.731411     72.264825  \n",
       "min         92.201000     -50.800000      0.634000   4963.600000  \n",
       "25%         93.075000     -42.700000      1.344000   5099.100000  \n",
       "50%         93.749000     -41.800000      4.857000   5191.000000  \n",
       "75%         93.994000     -36.400000      4.961000   5228.100000  \n",
       "max         94.767000     -26.900000      5.045000   5228.100000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label\n",
       "0      0\n",
       "1      0\n",
       "2      0\n",
       "3      0\n",
       "4      0\n",
       "5      0\n",
       "6      0\n",
       "7      0\n",
       "8      0\n",
       "9      0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = pd.DataFrame(y_train,columns=['label'])\n",
    "y_train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 32950 entries, 0 to 32949\n",
      "Data columns (total 1 columns):\n",
      "label    32950 non-null int64\n",
      "dtypes: int64(1)\n",
      "memory usage: 257.5 KB\n"
     ]
    }
   ],
   "source": [
    "y_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    29219\n",
       "1     3731\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f0e5b78fe10>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x='label',data=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = X_train.copy()\n",
    "data['label'] =  y_train[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.7/site-packages/statsmodels/nonparametric/kde.py:488: RuntimeWarning: invalid value encountered in true_divide\n",
      "  binned = fast_linbin(X, a, b, gridsize) / (delta * nobs)\n",
      "/usr/lib/python3.7/site-packages/statsmodels/nonparametric/kdetools.py:34: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  FAC1 = 2*(np.pi*bw/RANGE)**2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.PairGrid at 0x7f0e5b719048>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sns.pairplot(data,hue='label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.FacetGrid(data,hue=\"label\",size=5)\\\n",
    "    .map(sns.distplot,'age')\\\n",
    "    .add_legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.FacetGrid(data,hue=\"label\",size=8)\\\n",
    "    .map(sns.distplot,'campaign')\\\n",
    "    .add_legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.FacetGrid(data,hue=\"label\",size=8)\\\n",
    "    .map(sns.distplot,'previous')\\\n",
    "    .add_legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.jointplot(x='age' ,y='campaign',data=data,kind='kde')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x='label' ,y='campaign',data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x='label' ,y='age',data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from problem import get_test_data\n",
    "X_test ,y_test= get_test_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><center><a id=\"EL_040\"><h2>4. Models & Metrics</h2></a></center><br>\n",
    "\n",
    "In this part, we will present how both the models and the metrics are made and also how we build and test them.\n",
    "<br><br>\n",
    "\n",
    "<a id=\"EL_041\"><h3>4.1 Features engineering</h3></a>\n",
    "<br>\n",
    "\n",
    "We can notice that the dataset presents a very large number of features, considering that any of them might or might be not relevant. As we know, feature selection is a key step in data science when it allows avoiding working on useless features in input and thus, also allows to make simpler data-driven models with the direct advantage to get better predictive performances : indeed, we tend to avoid unwanted situations such as overfitting or giving importance to features that won't really correlate.\n",
    "\n",
    "The way we have designed our dataset usage is that performing manual selection of features by using the best domain knowledge is the most efficient way to achieve the best performances. Indeed, automatic methods can perform well but it's harder to get the best performances if we don't manually discard features we already know useless, because of the lack of such knowledge.\n",
    "As a result, semi-automatic methods will present a huge interest since they perform well and allow to manually discard features.\n",
    "\n",
    "In the output of the source code above, we have seen how to proceed with features extraction. The idea is to adapt a model to the available features by extracting them. Another way to see how to manage features will be shown below within source code.\n",
    "\n",
    "The main idea is to confirm a set of hypoteses (or disprove in the case didn't obtained the best set) with, ideally, only the most relevant features kept.\n",
    "\n",
    "To begin with the project, don't forget to look in the previous source code parts as most of the features we used should be available to watch.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"EL_042\"><h3>4.2 Classifiers</h3></a>\n",
    "\n",
    "### Baseline model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./img/workflow.png\" width=\"100%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we will aim to build two classes :\n",
    "- FeatureExtractor : containing features.\n",
    "- Classifier : contains the model to build.\n",
    "\n",
    "For more explanations, please refer to the part \"5.1 The model to submit\" as it summarizes the reasons of such implementation choices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An example `FeatureExtractor`, transforming categorical features to numeric features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.base import TransformerMixin\n",
    "\n",
    "\n",
    "class FeatureExtractor(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X_df, y):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X_df):\n",
    "        X_df_new = X_df.copy()\n",
    "        X_df_new.job.replace(('admin.','blue-collar','entrepreneur','housemaid','management','retired','self-employed','services','student','technician','unemployed','unknown'),(1,2,3,4,5,6,7,8,9,10,11,12), inplace=True)\n",
    "        X_df_new.marital.replace(('divorced','married','single','unknown'),(1,2,3,4), inplace=True)\n",
    "        X_df_new.education.replace(('basic.4y','basic.6y','basic.9y','high.school','illiterate','professional.course','university.degree','unknown'),(1,2,3,4,5,6,7,8), inplace=True)\n",
    "        X_df_new.default.replace(('no','yes','unknown'),(1,2,3), inplace=True)\n",
    "        X_df_new.housing.replace(('no','yes','unknown'),(1,2,3), inplace=True)\n",
    "        X_df_new.loan.replace(('no','yes','unknown'),(1,2,3), inplace=True)\n",
    "        X_df_new.contact.replace(('cellular','telephone'),(1,2), inplace=True)\n",
    "        X_df_new.month.replace(('jan','feb','mar','apr','may','jun','jul','aug','sep','oct','nov','dec'),(1,2,3,4,5,6,7,8,9,10,11,12), inplace=True)\n",
    "        X_df_new.day_of_week.replace(('mon','tue','wed','thu','fri'),(1,2,3,4,5), inplace=True)\n",
    "        X_df_new.poutcome.replace(('failure','nonexistent','success'),(1,2,3), inplace=True)\n",
    "        return X_df_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And an example Classifier doing a standard scaling and Logistic regression for the classification:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "class Classifier(BaseEstimator):\n",
    "    def __init__(self):\n",
    "        self.model = make_pipeline(StandardScaler(), MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(5, 2), random_state=1))\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.model.fit(X, y)\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        return self.model.predict_proba(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using thus model interactively in the notebook to fit on the training data and predict for the testing data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = make_pipeline(FeatureExtractor(), Classifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"EL_043\"><h3>4.3 Evaluation metrics</h3></a><br>\n",
    "\n",
    "In our project, we used two main metrics : the area of the LIFT cumulative curve (ALIFT) as the first metric, and the area of the receiver operating characteristic curve (AUC) as the second one. Indeed, when the models are tested on the evaluation set, those are the metrics we use.\n",
    "\n",
    "One of the reasons such metrics are used is that these are very popular metrics used in the industry and also can be easily combined with other metrics.\n",
    "As a quick example of why such metrics are chosen, the biggest advantage of using ROC curve (and so AUC) is that it's independent of the change in proportion of responders, which is a big advantage in our case.\n",
    "\n",
    "More concretely, in our project, we must assign a probabilistic outcome to our classes by giving a treshold such as considering an event is true only if it's higher than the defined treshold.\n",
    "\n",
    "To be clearer, we will continue with our previous example : the Receiver Operating Characteristic (ROC) curve is a metric of the  performance of a two class classifier (in our case fails and success) across the range of possible treshold value. The area under the curve (AUC) is then used for giving an overall accuracy, as it measures the degree of discrimination that we can obtain from the model we obtained from our classifier. Just as said before, AUC is a popular because it is independent of the class frequency or even the specific false or negative costs.\n",
    "The way to interpret this metric is that the more a method tends to an AUC of 1.0, the more perfect it is. The opposite works too in the way of that the more is tends to 0.0, the worst the method is. Logically, le more it tends to an AUC of 0.5, the more we can say that this classifier is a random one.\n",
    "\n",
    "In our case, we're working on a dataset related to marketing. In a such domain, the Lift analysis is also very popular for accessing the quality of targeting models.\n",
    "\n",
    "Usually, the population is divided into deciles, under a decreasing order of their predictive probability for success.\n",
    "In order to represent a LIFT cumulative curve, we usually plot the population samples against the cumulative percentage of real responses captured.\n",
    "Just like for the AUC metric, a perfect method will tend to present an area under the LIFT (ALIFT) cumulative curve close to 1.0. Again, a very bad method will tend to 0.0 while an ALIFT of 0.5 corresponds to what a random baseline is able to produce as performance.\n",
    "In a general way, we can interpret a high ALIFT as a confirmation of the predictive model to be able to concentrates the responders in the top decile. \n",
    "\n",
    "Moreover, it's interesting to know and summarize the differences between ROC and metrics like LIFT curve.\n",
    "Indeed, LIFT is dependent on total response rate of a given population. Hence, if the response rate of the population changes over time, the same model will give a different LIFT chart.\n",
    "A solution to this concern can be true to find the ratio of LIFT and perfect model LIFT at each decile. But such ratio rarely makes sense for the business.\n",
    "On the other hand, the ROC curve is almost independent of the response rate. If we try to plot the curve, we will see that both x and y axis will change on similar scale in the case of a response rate shift.\n",
    "\n",
    "Below, we will show some code presenting of we use the metrics in order to make evaluations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import log_loss,roc_curve,auc,classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_loss(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred.argmax(axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoded(class_numbers, num_classes=None):\n",
    "    if num_classes is None:\n",
    "        num_classes = np.max(class_numbers) + 1\n",
    "\n",
    "    return np.eye(num_classes, dtype=float)[class_numbers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "labels = one_hot_encoded(y_test,2)\n",
    "for i in range(2):\n",
    "    fpr[i], tpr[i], _ = roc_curve(labels[:,i], y_pred[:,i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), y_pred.argmax(axis=1).ravel())\n",
    "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(fpr[0], tpr[0], color='darkorange',\n",
    "         lw=lw, label='ROC curve of class 0 (area = %0.2f)' % roc_auc[0])\n",
    "plt.plot(fpr[1], tpr[1], color='b',\n",
    "         lw=lw, label='ROC curve of class 1 (area = %0.2f)' % roc_auc[1])\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation with Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import cross_validate\n",
    "from problem import get_cv\n",
    "\n",
    "def evaluation(X, y):\n",
    "    pipe = make_pipeline(FeatureExtractor(), Classifier())\n",
    "    cv = get_cv(X, y)\n",
    "    results = cross_validate(pipe, X, y, scoring=['roc_auc'], cv=cv,\n",
    "                             verbose=1, return_train_score=True,\n",
    "                             n_jobs=1)\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = evaluation(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training score Log Loss: {:.3f} +- {:.3f}\".format(-np.mean(results['train_roc_auc']),\n",
    "                                                        np.std(results['train_roc_auc'])))\n",
    "print(\"Testing score Log Loss: {:.3f} +- {:.3f} \\n\".format(-np.mean(results['test_roc_auc']),\n",
    "                                                          np.std(results['test_roc_auc'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"EL_044\"><h3>4.4 Testing</h3></a><br>\n",
    "\n",
    "As a logical consequence of everything that has been presented above, it's important to remember the fact of that when testing, depending of every aspect that was considered for the implementation of a classifier, the tests will have very variables results.\n",
    "\n",
    "Indeed, there is no universal technique. Hence, it's very important to take in count each aspect that has been introduced.\n",
    "The more relevant are the features taken in count (or in the other way : the more discarded are the useless features) as  the chosen methodology fits well, the more efficient the classifier will be in making good predictions in classification.\n",
    "\n",
    "\n",
    "The fact is that there is many implementations possibles.\n",
    "It's possible to implement an extremely basic classifier that will provide high computation speed but low results.\n",
    "It's also possible to implement a more realistic classifier that will produce better results.\n",
    "But in definitive, there is no other way than working on taking the most detailed, accurate in the chosen features and based on the problem domain knowledge classifier to get the best results. It's normal since every problem is unique and it's impossible in data science to just follow general techniques without tuning parameters or even analyze the data provided in order to take the best features at the best ratio.\n",
    "\n",
    "In conclusion on this subsection, it's very important to remember that the results of the tests will be directly linked to how good a classifier is able to generalize the problem on any test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><a id=\"EL_050\"><h2>5. The challenge</h2></a></center><br>\n",
    "\n",
    "<a id=\"EL_051\"><h3>5.1 The model to submit</h3></a>\n",
    "\n",
    "The submission consists of two files: `feature_extractor.py` which defines a `FeatureExtractor` class, and `classifier.py` which defines a `Classifier` class\n",
    "\n",
    "- `FeatureExtractor` can (optionally) hold code to calculate and add additional features.\n",
    "- `Classifier` fits the model and predicts on (new) data, as outputted by the `FeatureExtractor`. The prediction should be in the form of a (n_samples, 2) array with the probabilities of the two classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"EL_052\"><h3>5.2 Local testing (before submission)</h3></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is ** important that you test your submission files before submitting them **. For this we provide a unit test. Note that the test runs on your files in submissions/starting_kit, not on the classes defined in the cells of this notebook.<br><br>\n",
    "First pip install ramp-workflow or install it from the github repo. Make sure that the python files classifier.py and feature_extractor.py are in the  submissions/starting_kit folder, and the data data-train.csv, data-test.csv, label_train.npy, label_test.npy are in data. <br>\n",
    "Then run :\n",
    "** ramp_test_submission **<br>\n",
    "If it runs and print training and test errors on each fold, then you can submit the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!ramp_test_submission --submission starting_kit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"EL_053\"><h3>5.3 Submitting to the online challenge: [ramp.studio](http://ramp.studio)</h3></a><br>\n",
    "\n",
    "Once you found a good model, you can submit them to [ramp.studio](http://www.ramp.studio) to enter the online challenge. First, if it is your first time using the RAMP platform, [sign up](http://www.ramp.studio/sign_up), otherwise [log in](http://www.ramp.studio/login). Then sign up to the event [bank_marketing](http://www.ramp.studio/events/bank_marketing). Sign up for the event. Both signups are controled by RAMP administrators, so there **can be a delay between asking for signup and being able to submit**.\n",
    "\n",
    "Once your signup request is accepted, you can go to your [sandbox](http://www.ramp.studio/events/bank_marketing/sandbox) and copy-paste. You can also create a new starting-kit in the `submissions` folder containing both `feature_extractor.py` and `classifier.py` and upload those file directly. You can check the starting-kit ([`feature_extractor.py`](/edit/submissions/starting_kit/feature_extractor.py) and [`classifier.py`](/edit/submissions/starting_kit/classifier.py)) for an example. The submission is trained and tested on our backend in the similar way as `ramp_test_submission` does it locally. While your submission is waiting in the queue and being trained, you can find it in the \"New submissions (pending training)\" table in [my submissions](http://www.ramp.studio/events/bank_marketing/my_submissions). Once it is trained, you get a mail, and your submission shows up on the [public leaderboard](http://www.ramp.studio/events/bank_marketing/leaderboard). \n",
    "If there is an error (despite having tested your submission locally with `ramp_test_submission`), it will show up in the \"Failed submissions\" table in [my submissions](http://www.ramp.studio/events/bank_marketing/my_submissions). You can click on the error to see part of the trace.\n",
    "\n",
    "After submission, do not forget to give credits to the previous submissions you reused or integrated into your submission.\n",
    "\n",
    "The data set we use at the backend is usually different from what you find in the starting kit, so the score may be different.\n",
    "\n",
    "The usual way to work with RAMP is to explore solutions, add feature transformations, select models, perhaps do some AutoML/hyperopt, etc., _locally_, and checking them with `ramp_test_submission`. The script prints mean cross-validation scores \n",
    "\n",
    "The official score in this RAMP (the first score column after \"historical contributivity\" on the [leaderboard](http://www.ramp.studio/events/bank_marketing/leaderboard)) is the lift (`lift_metric`). When the score is good enough, you can submit it at the RAMP.\n",
    "\n",
    "<a id=\"EL_054\"><h3>5.4 More informations</h3></a>\n",
    "\n",
    "Don't forget you still can find more information in the README of the ramp-workflow library."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"EL_060\"><h2><center>6. Hints</center></h2></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Hints for features engineering and classifier "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "This Dataset is a quite complex business case because of the raw data structure and the prediction task. We give below some hints for further users of the Starting_kit to improve the score.\n",
    "<ul>\n",
    "<li>Consider other relevent metrics like roc_auc and f1-score due to the nature of dataset which is very unballanced</li>\n",
    "<li>Consider downsampling methods or outlier detection classifier</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Furthers hints "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading this paper might be useful if you're looking for more informations : http://media.salford-systems.com/video/tutorial/2015/targeted_marketing.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
